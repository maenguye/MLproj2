{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqyR-GmNFpzl",
    "outputId": "eccaf551-612a-41f1-d231-82c10e811ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from helpers import *\n",
    "from constants import *\n",
    "from NNmodels import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import  callbacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IY_NCkpsX0P",
    "outputId": "4966d14c-a11f-4dd6-8f64-4781344a2343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIfYl_jZFpzo"
   },
   "source": [
    "# Data extraction and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zv5spXK3Fpzo",
    "outputId": "212bc96e-f87b-4017-cf43-55ceb35fafd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "[[0.3254902  0.3019608  0.27058825]\n",
      " [0.31764707 0.28627452 0.25490198]\n",
      " [0.3137255  0.2901961  0.25490198]\n",
      " ...\n",
      " [0.31764707 0.31764707 0.29411766]\n",
      " [0.3137255  0.3137255  0.2901961 ]\n",
      " [0.31764707 0.31764707 0.3019608 ]]\n",
      "Loading 100 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = os.getcwd() + '/dataset/training/'\n",
    "data_filename = data_dir + \"images/\"\n",
    "labels_filename = data_dir + \"groundtruth/\"\n",
    "\n",
    "\n",
    "data, labels = load_data(data_filename, labels_filename, TRAINING_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RvkhNtzNd3AG"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_split = 0.7\n",
    "val_split = 0.15\n",
    "test_split = 0.15\n",
    "\n",
    "train_data = data[:int(train_split * len(data))]\n",
    "train_labels = labels[:int(train_split * len(labels))]\n",
    "val_data = data[int(train_split * len(data)) : int((train_split + val_split) * len(data))]\n",
    "val_labels = labels[int(train_split * len(labels)) : int((train_split + val_split) * len(labels))]\n",
    "test_data = data[int((train_split + val_split) * len(data)):]\n",
    "test_labels = labels[int((train_split + val_split) * len(labels)):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odSssImqFpzq"
   },
   "source": [
    "# Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1swwvi8sLvl"
   },
   "outputs": [],
   "source": [
    "model = CNN(input_shape=(100, 100, 3), num_classes=2)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Vsn6Twc0HkAF"
   },
   "outputs": [],
   "source": [
    "def create_generators(train_data, train_labels, val_data, val_labels, test_data, test_labels, WINDOW_SIZE, batch_size=32):\n",
    "\n",
    "    c_weights = {0: 2.8, 1: 1}\n",
    "\n",
    "    train_generator = image_generator(train_data,train_labels,WINDOW_SIZE,batch_size=batch_size,class_weights = c_weights)\n",
    "\n",
    "    val_generator = image_generator(val_data,val_labels,WINDOW_SIZE,batch_size=batch_size)\n",
    "\n",
    "    test_generator = image_generator(test_data,test_labels,WINDOW_SIZE,batch_size=batch_size)\n",
    "\n",
    "    return train_generator, val_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "otSPnWBpFpzq"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate= 0.0005),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMjv1NJ4Fpzr",
    "outputId": "e2f40147-2e0d-4e5c-f47a-163f0f40d82b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:593: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.6732 - loss: 8.5829 - val_accuracy: 0.6744 - val_loss: 1.3054 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.8107 - loss: 0.9489 - val_accuracy: 0.5306 - val_loss: 1.5571 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.8213 - loss: 0.6385 - val_accuracy: 0.6297 - val_loss: 0.8340 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.8336 - loss: 0.5559 - val_accuracy: 0.7800 - val_loss: 0.6201 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.8350 - loss: 0.5287 - val_accuracy: 0.7138 - val_loss: 0.7603 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.8414 - loss: 0.5041 - val_accuracy: 0.5100 - val_loss: 1.2393 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.8517 - loss: 0.4760 - val_accuracy: 0.5978 - val_loss: 1.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.8546 - loss: 0.4630 - val_accuracy: 0.5119 - val_loss: 0.9426 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8528 - loss: 0.4620 - val_accuracy: 0.6341 - val_loss: 0.7622 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.8656 - loss: 0.4329 - val_accuracy: 0.6331 - val_loss: 0.8949 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.8672 - loss: 0.4365 - val_accuracy: 0.6275 - val_loss: 0.9120 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.8749 - loss: 0.4127 - val_accuracy: 0.7278 - val_loss: 0.6200 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.8640 - loss: 0.4217 - val_accuracy: 0.7959 - val_loss: 0.5066 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.8647 - loss: 0.4265 - val_accuracy: 0.5303 - val_loss: 1.4936 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.8733 - loss: 0.4131 - val_accuracy: 0.7013 - val_loss: 0.7187 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.8709 - loss: 0.4060 - val_accuracy: 0.7828 - val_loss: 0.5722 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.8727 - loss: 0.4064 - val_accuracy: 0.7400 - val_loss: 0.8183 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.8674 - loss: 0.4179 - val_accuracy: 0.7437 - val_loss: 0.5809 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.8791 - loss: 0.3886 - val_accuracy: 0.7628 - val_loss: 0.6344 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.8785 - loss: 0.3899 - val_accuracy: 0.6750 - val_loss: 0.7548 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.8789 - loss: 0.3890 - val_accuracy: 0.6800 - val_loss: 0.8637 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8967 - loss: 0.3532 - val_accuracy: 0.7472 - val_loss: 0.7092 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.8883 - loss: 0.3725 - val_accuracy: 0.5141 - val_loss: 1.5891 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.8884 - loss: 0.3618 - val_accuracy: 0.7172 - val_loss: 0.6333 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.8900 - loss: 0.3614 - val_accuracy: 0.7731 - val_loss: 0.7702 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.8968 - loss: 0.3446 - val_accuracy: 0.5503 - val_loss: 1.3940 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9013 - loss: 0.3322 - val_accuracy: 0.8231 - val_loss: 0.4720 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9010 - loss: 0.3392 - val_accuracy: 0.8112 - val_loss: 0.5470 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9072 - loss: 0.3214 - val_accuracy: 0.6747 - val_loss: 0.8051 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.8992 - loss: 0.3265 - val_accuracy: 0.8322 - val_loss: 0.5010 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9012 - loss: 0.3227 - val_accuracy: 0.7972 - val_loss: 0.5637 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.3196 - val_accuracy: 0.6731 - val_loss: 0.9045 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9033 - loss: 0.3250 - val_accuracy: 0.6612 - val_loss: 0.9580 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9068 - loss: 0.3156 - val_accuracy: 0.7653 - val_loss: 0.6139 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9058 - loss: 0.3106 - val_accuracy: 0.7847 - val_loss: 0.5901 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9085 - loss: 0.3010 - val_accuracy: 0.6012 - val_loss: 1.3614 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9142 - loss: 0.3016 - val_accuracy: 0.7069 - val_loss: 0.8616 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9149 - loss: 0.2941 - val_accuracy: 0.6403 - val_loss: 1.1341 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9139 - loss: 0.2959 - val_accuracy: 0.7450 - val_loss: 0.7245 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9118 - loss: 0.2997 - val_accuracy: 0.8138 - val_loss: 0.4935 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9200 - loss: 0.2858 - val_accuracy: 0.6591 - val_loss: 0.9939 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9121 - loss: 0.2966 - val_accuracy: 0.6472 - val_loss: 0.9841 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9130 - loss: 0.2917 - val_accuracy: 0.7644 - val_loss: 0.6472 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9172 - loss: 0.2784 - val_accuracy: 0.7331 - val_loss: 0.8316 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9165 - loss: 0.2822 - val_accuracy: 0.7125 - val_loss: 0.7976 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m549/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9223 - loss: 0.2733\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9223 - loss: 0.2733 - val_accuracy: 0.7597 - val_loss: 0.6573 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9239 - loss: 0.2586 - val_accuracy: 0.8475 - val_loss: 0.4250 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9293 - loss: 0.2411 - val_accuracy: 0.7984 - val_loss: 0.5931 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9339 - loss: 0.2390 - val_accuracy: 0.8494 - val_loss: 0.4371 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9316 - loss: 0.2342 - val_accuracy: 0.7247 - val_loss: 0.7103 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9343 - loss: 0.2279 - val_accuracy: 0.8078 - val_loss: 0.5114 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9365 - loss: 0.2230 - val_accuracy: 0.7722 - val_loss: 0.5672 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9334 - loss: 0.2300 - val_accuracy: 0.8319 - val_loss: 0.4288 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9310 - loss: 0.2330 - val_accuracy: 0.7581 - val_loss: 0.6068 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.9322 - loss: 0.2243 - val_accuracy: 0.8147 - val_loss: 0.5234 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9331 - loss: 0.2213 - val_accuracy: 0.8650 - val_loss: 0.3921 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9320 - loss: 0.2268 - val_accuracy: 0.7741 - val_loss: 0.7546 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9343 - loss: 0.2203 - val_accuracy: 0.8103 - val_loss: 0.5242 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9385 - loss: 0.2138 - val_accuracy: 0.8147 - val_loss: 0.5821 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9340 - loss: 0.2215 - val_accuracy: 0.7978 - val_loss: 0.5780 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9434 - loss: 0.2009 - val_accuracy: 0.8419 - val_loss: 0.4381 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9307 - loss: 0.2217 - val_accuracy: 0.6803 - val_loss: 1.4785 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9404 - loss: 0.2051 - val_accuracy: 0.7647 - val_loss: 0.9168 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.9412 - loss: 0.2052 - val_accuracy: 0.8191 - val_loss: 0.5957 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9415 - loss: 0.2044 - val_accuracy: 0.7100 - val_loss: 0.8086 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9358 - loss: 0.2132 - val_accuracy: 0.7631 - val_loss: 0.7018 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9387 - loss: 0.2165 - val_accuracy: 0.8697 - val_loss: 0.3951 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9367 - loss: 0.2121 - val_accuracy: 0.8081 - val_loss: 0.5068 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9340 - loss: 0.2151 - val_accuracy: 0.8737 - val_loss: 0.3418 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9422 - loss: 0.2060 - val_accuracy: 0.7194 - val_loss: 0.9964 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9415 - loss: 0.2073 - val_accuracy: 0.8428 - val_loss: 0.4379 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9376 - loss: 0.2146 - val_accuracy: 0.7847 - val_loss: 0.6271 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9426 - loss: 0.1964 - val_accuracy: 0.7697 - val_loss: 0.7299 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9433 - loss: 0.1997 - val_accuracy: 0.7956 - val_loss: 0.6311 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9328 - loss: 0.2181 - val_accuracy: 0.8416 - val_loss: 0.4718 - learning_rate: 2.5000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9409 - loss: 0.1988 - val_accuracy: 0.7841 - val_loss: 0.5646 - learning_rate: 2.5000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9394 - loss: 0.2049 - val_accuracy: 0.7494 - val_loss: 0.8282 - learning_rate: 2.5000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9324 - loss: 0.2245 - val_accuracy: 0.8494 - val_loss: 0.4536 - learning_rate: 2.5000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9399 - loss: 0.2038 - val_accuracy: 0.8403 - val_loss: 0.4825 - learning_rate: 2.5000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9385 - loss: 0.2109 - val_accuracy: 0.8209 - val_loss: 0.4871 - learning_rate: 2.5000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9370 - loss: 0.2118 - val_accuracy: 0.8128 - val_loss: 0.4895 - learning_rate: 2.5000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9374 - loss: 0.2117\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9374 - loss: 0.2117 - val_accuracy: 0.8278 - val_loss: 0.4696 - learning_rate: 2.5000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.9511 - loss: 0.1795 - val_accuracy: 0.8778 - val_loss: 0.3710 - learning_rate: 1.2500e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9508 - loss: 0.1748 - val_accuracy: 0.8797 - val_loss: 0.3621 - learning_rate: 1.2500e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9493 - loss: 0.1802 - val_accuracy: 0.8316 - val_loss: 0.5545 - learning_rate: 1.2500e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9527 - loss: 0.1698 - val_accuracy: 0.8550 - val_loss: 0.4630 - learning_rate: 1.2500e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9556 - loss: 0.1653 - val_accuracy: 0.8347 - val_loss: 0.5724 - learning_rate: 1.2500e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9514 - loss: 0.1719 - val_accuracy: 0.8472 - val_loss: 0.4491 - learning_rate: 1.2500e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.9514 - loss: 0.1730 - val_accuracy: 0.8616 - val_loss: 0.4439 - learning_rate: 1.2500e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9503 - loss: 0.1741 - val_accuracy: 0.8675 - val_loss: 0.4312 - learning_rate: 1.2500e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m551/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9522 - loss: 0.1700\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9522 - loss: 0.1700 - val_accuracy: 0.8325 - val_loss: 0.5566 - learning_rate: 1.2500e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9481 - loss: 0.1750 - val_accuracy: 0.8697 - val_loss: 0.3891 - learning_rate: 6.2500e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9544 - loss: 0.1561 - val_accuracy: 0.8675 - val_loss: 0.3977 - learning_rate: 6.2500e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9621 - loss: 0.1466 - val_accuracy: 0.8553 - val_loss: 0.5323 - learning_rate: 6.2500e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9599 - loss: 0.1430 - val_accuracy: 0.8328 - val_loss: 0.5494 - learning_rate: 6.2500e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9589 - loss: 0.1462 - val_accuracy: 0.8316 - val_loss: 0.5734 - learning_rate: 6.2500e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.9624 - loss: 0.1402 - val_accuracy: 0.8441 - val_loss: 0.6087 - learning_rate: 6.2500e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9569 - loss: 0.1508 - val_accuracy: 0.8313 - val_loss: 0.6563 - learning_rate: 6.2500e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m549/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9563 - loss: 0.1535\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9563 - loss: 0.1535 - val_accuracy: 0.8447 - val_loss: 0.5757 - learning_rate: 6.2500e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m552/552\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9571 - loss: 0.1519 - val_accuracy: 0.8572 - val_loss: 0.4551 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "# Early stopping callback\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='accuracy',  # Monitor validation loss\n",
    "    patience=10,  # Stop training after 5 epochs without improvement\n",
    "    restore_best_weights=True)  # Restore weights of the best epoch)\n",
    "\n",
    "lr_callback = ReduceLROnPlateau(monitor='accuracy', factor=0.5, patience=5,\n",
    "                                verbose=1, mode='auto', min_delta=0, cooldown=0, min_lr=0)\n",
    "\n",
    "#train_generator = create_generators(train_data_split, train_label_split , validation_data_split,validation_label_split, 100,batch_size=32)\n",
    "train_generator, val_generator, test_generator = create_generators(train_data,\n",
    "                                                                    train_labels ,\n",
    "                                                                      val_data,val_labels,\n",
    "                                                                          test_data,\n",
    "                                                                              test_labels,\n",
    "                                                                                  100,\n",
    "                                                                                      batch_size=32)\n",
    "\n",
    "\n",
    "history = model.fit(train_generator, validation_data=val_generator,\n",
    "                    steps_per_epoch=int((len(train_data))),\n",
    "                    validation_steps=100,\n",
    "                      epochs=100,\n",
    "                      callbacks=[early_stopping, lr_callback],\n",
    "                      verbose=1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MLCourse1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
