{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 09:24:29.844292: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "import code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.python.platform\n",
    "import sys\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3  # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 32  # 64\n",
    "IMG_PATCH_SIZE = 16\n",
    "TRAINING_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_crop(im, w, h):\n",
    "    '''\n",
    "    Crop an image into patches of size w x h\n",
    "    '''\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0, imgheight, h):\n",
    "        for j in range(0, imgwidth, w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j : j + w, i : i + h]\n",
    "            else:\n",
    "                im_patch = im[j : j + w, i : i + h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25  # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:  # road\n",
    "        return [0, 1]\n",
    "    else:  # bgrd\n",
    "        return [1, 0]\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    for i in range(1, num_images + 1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            # print(\"Loading \" + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            # Normalize\n",
    "            img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print(\"File \" + image_filename + \" does not exist\")\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH / IMG_PATCH_SIZE) * (IMG_HEIGHT / IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [\n",
    "        img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)\n",
    "    ] # list of list of patches, each list of patches corresponds to one image\n",
    "    data = [\n",
    "        img_patches[i][j]\n",
    "        for i in range(len(img_patches))\n",
    "        for j in range(len(img_patches[i]))\n",
    "    ] # flatten the list of patches\n",
    "\n",
    "    return numpy.asarray(data)\n",
    "\n",
    "def cropped_imgs(images, patch_size):\n",
    "    '''\n",
    "    Crop the labels into patches of size patch_size x patch_size\n",
    "    '''\n",
    "    imgs_patches = [\n",
    "        img_crop(images[i], patch_size, patch_size) for i in range(len(images))\n",
    "    ]\n",
    "    return numpy.asarray(\n",
    "        [\n",
    "            imgs_patches[i][j]\n",
    "            for i in range(len(imgs_patches))\n",
    "            for j in range(len(imgs_patches[i]))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "def cropped_labels(labels, patch_size):\n",
    "\n",
    "    labels_patches = [\n",
    "        img_crop(labels[i], patch_size, patch_size) for i in range(len(labels))\n",
    "    ]\n",
    "\n",
    "    data = numpy.asarray(\n",
    "        [ \n",
    "            labels_patches[i][j]\n",
    "            for i in range(len(labels_patches))\n",
    "            for j in range(len(labels_patches[i]))\n",
    "        ]\n",
    "    )\n",
    "    labels = np.asarray(\n",
    "        [value_to_class(np.mean(data[i])) for i in range(len(data))]\n",
    "    )\n",
    "    \n",
    "    return labels.astype(numpy.float32)\n",
    "    \n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images + 1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            # print(\"Loading \" + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print(\"File \" + image_filename + \" does not exist\")\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [\n",
    "        img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)\n",
    "    ]\n",
    "    data = numpy.asarray(\n",
    "        [\n",
    "            gt_patches[i][j]\n",
    "            for i in range(len(gt_patches))\n",
    "            for j in range(len(gt_patches[i]))\n",
    "        ]\n",
    "    )\n",
    "    labels = numpy.asarray(\n",
    "        [value_to_class(numpy.mean(data[i])) for i in range(len(data))]\n",
    "    )\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "[[0.3254902  0.3019608  0.27058825]\n",
      " [0.31764707 0.28627452 0.25490198]\n",
      " [0.3137255  0.2901961  0.25490198]\n",
      " ...\n",
      " [0.31764707 0.31764707 0.29411766]\n",
      " [0.3137255  0.3137255  0.2901961 ]\n",
      " [0.31764707 0.31764707 0.3019608 ]]\n",
      "Loading 100 images\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + '/dataset/training/'\n",
    "data_filename = data_dir + \"images/\"\n",
    "labels_filename = data_dir + \"groundtruth/\"\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def load_data(image_dir, gt_dir, training_size):\n",
    "      files = image_dir + 'satImage_'\n",
    "      #n = len(files)\n",
    "      n = 100\n",
    "      print(\"Loading \" + str(n) + \" images\")\n",
    "      imgs = [load_image(files + '%.3d' % i + '.png') for i in range(1,n)]\n",
    "      print(imgs[0][2])\n",
    "\n",
    "      gt_dir =gt_dir + 'satImage_'\n",
    "      print(\"Loading \" + str(n) + \" images\")\n",
    "      gt_imgs = [load_image(gt_dir + '%.3d' % i + '.png') for i in range(1,n)]\n",
    "\n",
    "      X_train = imgs\n",
    "      Y_train = gt_imgs\n",
    "      return X_train, Y_train\n",
    "\n",
    "X, Y = load_data(data_filename, labels_filename, TRAINING_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "train_size = int(train_ratio * TRAINING_SIZE)\n",
    "\n",
    "X_train = X[:train_size]\n",
    "Y_train = Y[:train_size]\n",
    "\n",
    "X_val = X[train_size:train_size + int(val_ratio * TRAINING_SIZE)]\n",
    "Y_val = Y[train_size:train_size + int(val_ratio * TRAINING_SIZE)]\n",
    "\n",
    "X_test = X[train_size + int(val_ratio * TRAINING_SIZE):]\n",
    "Y_test = Y[train_size + int(val_ratio * TRAINING_SIZE):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = cropped_imgs(X_train, 16)\n",
    "train_labels = cropped_labels(Y_train, 16)\n",
    "val_data = cropped_imgs(X_val, 16)\n",
    "val_labels = cropped_labels(Y_val, 16)\n",
    "test_data = cropped_imgs(X_test, 16)\n",
    "test_labels = cropped_labels(Y_test, 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing training data...\n",
      "Number of data points per class: c0 = 32663, c1 = 11087\n",
      "Balanced dataset size: 22174\n"
     ]
    }
   ],
   "source": [
    "# Balance the classes.\n",
    "print(\"Balancing training data...\")\n",
    "c0 = np.sum(train_labels[:, 0] == 1) # Count the number of data points in class 0\n",
    "c1 = np.sum(train_labels[:, 1] == 1) # Count the number of data points in class 1\n",
    "print(f\"Number of data points per class: c0 = {c0}, c1 = {c1}\")\n",
    "min_c = min(c0, c1)\n",
    "idx0 = np.where(train_labels[:, 0] == 1)[0][:min_c] # Get the indices of the first class\n",
    "idx1 = np.where(train_labels[:, 1] == 1)[0][:min_c] # Get the indices of the second class\n",
    "balanced_indices = np.concatenate([idx0, idx1]) \n",
    "train_data = train_data[balanced_indices] \n",
    "train_labels = train_labels[balanced_indices]\n",
    "    \n",
    "print(f\"Balanced dataset size: {train_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ..............................................C=0.1; total time= 3.6min\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Define a custom scorer using F1-score (or other metrics)\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# Hyperparameter grid to tune\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],        # Regularization parameter\n",
    "}\n",
    "\n",
    "# Reshape train data\n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n",
    "train_labels_flat = np.argmax(train_labels, axis=1)\n",
    "\n",
    "# Create the SVM model\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Use GridSearchCV to tune hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    svc, \n",
    "    param_grid, \n",
    "    scoring=scorer, \n",
    "    cv=5,   # 5-fold cross-validation\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(train_data, train_labels_flat)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(train_data)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(train_labels_flat, predictions)\n",
    "f1 = f1_score(train_labels_flat, predictions, average='weighted')\n",
    "precision = precision_score(train_labels_flat, predictions, average='weighted')\n",
    "recall = recall_score(train_labels_flat, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels of the test set\n",
    "test_data = test_data.reshape(test_data.shape[0], -1)\n",
    "predicted_labels = svm.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1, 0.43212917350848384, accuracy, 0.5257142857142857, precision, 0.304473582722715, recall, 0.7441093308199811\n"
     ]
    }
   ],
   "source": [
    "# evaluate the classifier\n",
    "accuracy = accuracy_score(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "precision = precision_score(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "recall = recall_score(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "f1 = f1_score(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "\n",
    "# use \n",
    "\n",
    "print(f\"f1, {f1}, accuracy, {accuracy}, precision, {precision}, recall, {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melina/.virtualenvs/base-venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Reshape train data\n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n",
    "train_labels_flat = np.argmax(train_labels, axis=1)\n",
    "\n",
    "# Define a custom scorer (e.g., F1-score)\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  # Regularization strength\n",
    "}\n",
    "\n",
    "# Create the logistic regression model\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    logreg, \n",
    "    param_grid, \n",
    "    scoring=scorer, \n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(train_data, train_labels_flat)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(train_data)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(train_labels_flat, predictions)\n",
    "f1 = f1_score(train_labels_flat, predictions, average='weighted')\n",
    "precision = precision_score(train_labels_flat, predictions, average='weighted')\n",
    "recall = recall_score(train_labels_flat, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1, 0.4184859654096966, accuracy, 0.5312\n"
     ]
    }
   ],
   "source": [
    "# predict the labels of the test set\n",
    "predicted_labels = logreg.predict(test_data)\n",
    "f1_log = f1_score(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "accuracy_log = accuracy_score(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "\n",
    "print(f\"f1, {f1_log}, accuracy, {accuracy_log}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
